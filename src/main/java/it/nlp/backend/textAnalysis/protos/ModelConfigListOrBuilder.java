// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tfmodels.proto

package it.nlp.backend.textAnalysis.protos;

public interface ModelConfigListOrBuilder extends
    // @@protoc_insertion_point(interface_extends:tensorflow.serving.ModelConfigList)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <code>repeated .tensorflow.serving.ModelConfig config = 1;</code>
   */
  java.util.List<it.nlp.backend.textAnalysis.protos.ModelConfig> 
      getConfigList();
  /**
   * <code>repeated .tensorflow.serving.ModelConfig config = 1;</code>
   */
  it.nlp.backend.textAnalysis.protos.ModelConfig getConfig(int index);
  /**
   * <code>repeated .tensorflow.serving.ModelConfig config = 1;</code>
   */
  int getConfigCount();
  /**
   * <code>repeated .tensorflow.serving.ModelConfig config = 1;</code>
   */
  java.util.List<? extends it.nlp.backend.textAnalysis.protos.ModelConfigOrBuilder> 
      getConfigOrBuilderList();
  /**
   * <code>repeated .tensorflow.serving.ModelConfig config = 1;</code>
   */
  it.nlp.backend.textAnalysis.protos.ModelConfigOrBuilder getConfigOrBuilder(
      int index);
}
